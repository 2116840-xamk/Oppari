{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef9efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 13:06:39 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f99fc5a312d43efbe27cd788d29a82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 13:06:39 INFO: Downloaded file to C:\\Users\\huvif\\stanza_resources\\resources.json\n",
      "2025-08-11 13:06:39 WARNING: Language fi package default expects mwt, which has been added\n",
      "2025-08-11 13:06:39 INFO: Loading these models for language: fi (Finnish):\n",
      "============================\n",
      "| Processor | Package      |\n",
      "----------------------------\n",
      "| tokenize  | tdt          |\n",
      "| mwt       | tdt          |\n",
      "| pos       | tdt_charlm   |\n",
      "| lemma     | tdt_nocharlm |\n",
      "============================\n",
      "\n",
      "2025-08-11 13:06:39 INFO: Using device: cpu\n",
      "2025-08-11 13:06:39 INFO: Loading: tokenize\n",
      "2025-08-11 13:06:39 INFO: Loading: mwt\n",
      "2025-08-11 13:06:39 INFO: Loading: pos\n",
      "2025-08-11 13:06:40 INFO: Loading: lemma\n",
      "2025-08-11 13:06:41 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  otsikko                                             teksti         tunne  \\\n",
      "0     NaN  Ostin hyvästä tarjouksesta pesukoneen asennuks...  positiivinen   \n",
      "1     NaN  Ensimmäiset viikot pyykätty ja tuntuisi olevan...  positiivinen   \n",
      "2     NaN  Onhan näissä koneissa eroa kun ostaa 300€ kone...  positiivinen   \n",
      "3     NaN  Vasta kaksi kertaa käytetty: mix -ohjelma ja l...  positiivinen   \n",
      "4     NaN  Hommattiin pari viikkoa sitten ja oikeastaan s...  positiivinen   \n",
      "\n",
      "                                                 url  tähdet?  \n",
      "0  https://www.gigantti.fi/product/kodinkoneet/py...  5.touko  \n",
      "1  https://www.gigantti.fi/product/kodinkoneet/py...  4.touko  \n",
      "2  https://www.gigantti.fi/product/kodinkoneet/py...  5.touko  \n",
      "3  https://www.gigantti.fi/product/kodinkoneet/py...  4.touko  \n",
      "4  https://www.gigantti.fi/product/kodinkoneet/py...  5.touko  \n",
      "                                              teksti  \\\n",
      "0  Ostin hyvästä tarjouksesta pesukoneen asennuks...   \n",
      "1  Ensimmäiset viikot pyykätty ja tuntuisi olevan...   \n",
      "2  Onhan näissä koneissa eroa kun ostaa 300€ kone...   \n",
      "3  Vasta kaksi kertaa käytetty: mix -ohjelma ja l...   \n",
      "4  Hommattiin pari viikkoa sitten ja oikeastaan s...   \n",
      "\n",
      "                                     lemmatized_text  \n",
      "0  ostaa hyvä tarjous pesu#kone asennus ja kuljet...  \n",
      "1  ensimmäinen viikko pyykätä ja tuntua olla minä...  \n",
      "2  olla tämä kone ero kun ostaa 300 € kone tilall...  \n",
      "3  vasta kaksi kerta käyttää : mix ohjelma ja lyh...  \n",
      "4  hommata pari viikko sitten ja oikeastaan se lä...  \n",
      "Accuracy: 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "negatiivinen       0.60      0.50      0.55         6\n",
      "   neutraali       1.00      0.33      0.50         3\n",
      "positiivinen       0.71      0.91      0.80        11\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.77      0.58      0.62        20\n",
      "weighted avg       0.72      0.70      0.68        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import stanza\n",
    "\n",
    "#Stanza pipeline suomen kieltä varten\n",
    "nlp = stanza.Pipeline('fi', processors='tokenize,pos,lemma', use_gpu=False)\n",
    "\n",
    "#Funktio tekstin lemmatisointia varten\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_words = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Aineisto\n",
    "df = pd.read_csv('arvostelut.csv', delimiter=';', quoting=0)\n",
    "print(df.head())\n",
    "\n",
    "#Lemmatisoinnin sovellus\n",
    "df['lemmatized_text'] = df['teksti'].apply(lemmatize_text)\n",
    "#print(df[['teksti', 'lemmatized_text']].head())\n",
    "# Syöte X, data jonka avulla malli oppii. Kohde y, se mitä mallin tulee oppia ennustamaan.\n",
    "X = df['lemmatized_text']\n",
    "#X = df['teksti']\n",
    "y = df['tunne']\n",
    "\n",
    "# train_test_split sekoittaa datan ja jakaa sen neljään osaan: X_train ja y_train opetusdata, X_test ja y_test testidata\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=77, stratify=y\n",
    ")\n",
    "\n",
    "# Pipeline: TF-IDF + Logistic Regression\n",
    "from sklearn.pipeline import Pipeline #ketjuttaa datan muokkausvaiheet ja malli yhteen pakettiin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), #vastaanottaa tekstin ja muuttaa sen numeroiksi TF-IDF:n avulla\n",
    "    ('clf', LogisticRegression(class_weight='balanced')), #Luokittelija, ottaa vastaan TfidVectorizer:n tuottaman numerodatan ja tekee ennusteita sen perusteella. \n",
    "    #('clf', MultinomialNB()),\n",
    "    #('clf', LinearSVC(class_weight='balanced', dual=\"auto\")),\n",
    "])\n",
    "\n",
    "\n",
    "text_clf.fit(X_train, y_train) #.fit() komento syöttää opetusdatan X_train ja y_train putken läpi, TfidVectorizer analysoi X_trainin sanat ja luo sanaston sekä laskee TF-IDF arvot.\n",
    "\n",
    "#Numerodata ja vastaukset y_train syötetään mallille joka oppii mitkä sanat liittyvät mihinkin tunteeseen\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "predictions = text_clf.predict(X_test) #Ennusteet testidatalla\n",
    "#Tulostetaan raportti\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144ed0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alustetaan Stanza-putkea (voi kestää hetken)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-24 23:18:23 WARNING: Language fi package default expects mwt, which has been added\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanza-putki valmis.\n",
      "Ladataan prototyypin opetusdataa (arvostelut.csv)...\n",
      "Ladataan uutta, suurta aineistoa (complete_reviews.csv)...\n",
      "Esikäsitellään dataa (lemmatisoidaan ja yhdistetään otsikot)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huvif\\AppData\\Local\\Temp\\ipykernel_25044\\2139538703.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train_prototype['otsikko'].fillna('', inplace=True) # Korvataan tyhjät otsikot\n",
      "C:\\Users\\huvif\\AppData\\Local\\Temp\\ipykernel_25044\\2139538703.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_new_reviews['otsikko'].fillna('', inplace=True) # Korvataan tyhjät otsikot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esikäsittely valmis.\n",
      "Koulutetaan prototyyppimalli...\n",
      "Prototyyppimalli koulutettu.\n",
      "Tehdään ennusteita uudelle aineistolle...\n",
      "Tiedosto 1 tallennettu nimellä: mallin_luomat_tunnearvot.csv\n",
      "Luodaan tunnearvoja tähtien perusteella...\n",
      "Tiedosto 2 tallennettu nimellä: tahtien_perusteella_annetut_tunnearvot.csv\n",
      "\n",
      "Valmis! Voit nyt avata ja vertailla luotuja CSV-tiedostoja.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import stanza\n",
    "import requests\n",
    "\n",
    "# ==============================================================================\n",
    "# VAIHE 0: ALUSTUKSET (kuten aiemmin)\n",
    "# ==============================================================================\n",
    "\n",
    "# Stanza pipeline (ladataan vain kerran)\n",
    "print(\"Alustetaan Stanza-putkea (voi kestää hetken)...\")\n",
    "nlp = stanza.Pipeline('fi', processors='tokenize,lemma', use_gpu=False, logging_level='WARN')\n",
    "print(\"Stanza-putki valmis.\")\n",
    "\n",
    "# Stop-sanojen lataus ja karsinta\n",
    "url = \"https://raw.githubusercontent.com/stopwords-iso/stopwords-fi/master/stopwords-fi.txt\"\n",
    "response = requests.get(url)\n",
    "finnish_stop_words = response.text.splitlines()\n",
    "suodatus = {'ei', 'eikä', 'mutta', 'vaan', 'vaikka', 'jos', 'kuin'}\n",
    "custom_stop_words = [word for word in finnish_stop_words if word not in suodatus]\n",
    "custom_stop_words.append('placeholder') #tyhjien otsikoiden tilalle laitettu teksti\n",
    "\n",
    "# Lemmatisointifunktio\n",
    "def lemmatize_text(text):\n",
    "    # Varmistetaan, että syöte on merkkijono\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    doc = nlp(text)\n",
    "    lemmatized_words = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# ==============================================================================\n",
    "# VAIHE 1: DATAN LATAUS JA VALMISTELU\n",
    "# ==============================================================================\n",
    "\n",
    "# Ladataan vanha, manuaalisesti leimattu aineisto mallin koulutusta varten\n",
    "print(\"Ladataan prototyypin opetusdataa (arvostelut.csv)...\")\n",
    "df_train_prototype = pd.read_csv('arvostelut.csv', delimiter=';', quoting=0)\n",
    "\n",
    "# Ladataan uusi, suuri ja leimaamaton aineisto\n",
    "print(\"Ladataan uutta, suurta aineistoa (complete_reviews.csv)...\")\n",
    "df_new_reviews = pd.read_csv('complete_reviews.csv')\n",
    "\n",
    "# --- Datan esikäsittely ---\n",
    "print(\"Esikäsitellään dataa (lemmatisoidaan ja yhdistetään otsikot)...\")\n",
    "\n",
    "# Prototyypin opetusdata\n",
    "df_train_prototype['otsikko'].fillna('', inplace=True) # Korvataan tyhjät otsikot\n",
    "df_train_prototype['lemmatized_text'] = df_train_prototype.apply(lambda row: lemmatize_text(row['otsikko'] + ' ' + row['teksti']), axis=1)\n",
    "\n",
    "# Uusi suuri data\n",
    "df_new_reviews['otsikko'].fillna('', inplace=True) # Korvataan tyhjät otsikot\n",
    "df_new_reviews['lemmatized_text'] = df_new_reviews.apply(lambda row: lemmatize_text(row['otsikko'] + ' ' + row['teksti']), axis=1)\n",
    "\n",
    "print(\"Esikäsittely valmis.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# VAIHE 2: TIEDOSTO 1 - OHJELMAN LUOMAT TUNNEARVOT\n",
    "# ==============================================================================\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Määritellään ja koulutetaan prototyyppimalli\n",
    "print(\"Koulutetaan prototyyppimalli...\")\n",
    "X_train_proto = df_train_prototype['lemmatized_text']\n",
    "y_train_proto = df_train_prototype['tunne']\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=custom_stop_words)),\n",
    "    ('clf', LogisticRegression(class_weight='balanced')),\n",
    "])\n",
    "\n",
    "text_clf.fit(X_train_proto, y_train_proto)\n",
    "print(\"Prototyyppimalli koulutettu.\")\n",
    "\n",
    "# Tehdään ennusteet koko uudelle aineistolle\n",
    "print(\"Tehdään ennusteita uudelle aineistolle...\")\n",
    "X_new = df_new_reviews['lemmatized_text']\n",
    "predicted_sentiments = text_clf.predict(X_new)\n",
    "\n",
    "# Lisätään ennusteet uuteen DataFrameen ja tallennetaan\n",
    "df_model_predictions = df_new_reviews.copy()\n",
    "df_model_predictions['mallin_ennuste'] = predicted_sentiments\n",
    "\n",
    "output_filename_1 = 'mallin_luomat_tunnearvot.csv'\n",
    "df_model_predictions.to_csv(output_filename_1, index=False, encoding='utf-8-sig')\n",
    "print(f\"Tiedosto 1 tallennettu nimellä: {output_filename_1}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# VAIHE 3: TIEDOSTO 2 - TÄHTIEN PERUSTEELLA ANNETUT TUNNEARVOT\n",
    "# ==============================================================================\n",
    "\n",
    "def stars_to_sentiment(rating):\n",
    "    \"\"\"Muuttaa tähtiarvion (1-5) tunnesanaksi.\"\"\"\n",
    "    try:\n",
    "        # Yritetään muuttaa arvo numeroksi. Gigantin '5.touko' muuttuu numeroksi 5.\n",
    "        rating = int(float(rating)) \n",
    "        if rating <= 2:\n",
    "            return 'negatiivinen'\n",
    "        elif rating == 3:\n",
    "            return 'neutraali'\n",
    "        elif rating >= 4:\n",
    "            return 'positiivinen'\n",
    "    except (ValueError, TypeError):\n",
    "        # Jos muunnos epäonnistuu (esim. tekstiä tai tyhjä), palautetaan N/A\n",
    "        return 'N/A'\n",
    "\n",
    "print(\"Luodaan tunnearvoja tähtien perusteella...\")\n",
    "# Luodaan uusi DataFrame, johon lisätään tähtipohjaiset tunnearvot\n",
    "df_star_sentiments = df_new_reviews.copy()\n",
    "df_star_sentiments['tahtien_tunne'] = df_star_sentiments['tahdet'].apply(stars_to_sentiment)\n",
    "\n",
    "output_filename_2 = 'tahtien_perusteella_annetut_tunnearvot.csv'\n",
    "df_star_sentiments.to_csv(output_filename_2, index=False, encoding='utf-8-sig')\n",
    "print(f\"Tiedosto 2 tallennettu nimellä: {output_filename_2}\")\n",
    "\n",
    "print(\"\\nValmis! Voit nyt avata ja vertailla luotuja CSV-tiedostoja.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
